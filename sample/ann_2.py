
"""
Description
---------
Module of construction of ANN. It's written by pure Python3.
"""

import numpy as np
from random import uniform
from copy import deepcopy


# Typing Hint
# ----------------------
from typing import List

Weights = List[List[List[float]]]

Outputs = List[List[float]]

# ----------------------


def sigmoid(x: float) -> float:
    
    return 1 / (1 + np.exp(-x))


def dot(x: List[float], y: List[float]) -> float:
    
    assert len(x) == len(y)
    
    dim = len(x)
    
    return sum([x[i] * y[i] for i in range(dim)])


class NeuralNetwork(object):
    """
    Description
    ---------
    ALL information of a NeuralNetwork itself is contained in its weight-table
    which is `self.weights`. If you want to modify a NeuralNetwork, then just
    modify the weight-table (`self.weights`). This table is arranged as Weights,
    which is List[List[List[float]]]. Explicitly, it is
                 
            self.weights[layer_number][perceptron_number][weight_number]
    

    ALL information of output of a NeuralNetwork is contained in its output-table
    which is generated by `self.output`. This table is arranged as Outputs,
    which is List[List[float]]. Explicitly, it is
                 
            self.outputs(inputs)[layer_number][perceptron_number]
    
    
    Parameters
    ---------
    size:
        The number of perceptrons on each layer, excluding the input-layer.
    
    input_size:
        The number of inputs on the input-layer.
        
    E.g. size = [2, 1], and input_size = 2:
            
            o --- o
             \   /  \
               x     o --
             /   \  /
            o --- o
    
    Notations
    ---------
    l : layer
    p : perceptron
    w : weight
    o : output
    """
    
    def __init__(self, size: List[int],
                 input_size: int,
                 trans_function=sigmoid
                 ) -> None:
        
        for num in size:
            assert num > 0, "elements of `size` shall be positive."
            
        assert input_size > 0, "`input_size` shall be positive."
        
        self.size = size
        
        self.input_size = input_size
        
        self.trans_function = trans_function
                
        # Generate Weights table
        self.weights = []
        
        for l in range(len(self.size)):
            
            layer = []
            
            if l == 0:                
                for p in range(self.size[l]):
                    # do not forget the threshold (the last weight)
                    perceptron = [uniform(-0.05, 0.05)
                                  for w in range(self.input_size + 1)
                                  ]
                    
                    layer.append(perceptron)
                    
            else:
                for p in range(self.size[l]):
                    # do not forget the threshold (the last weight)
                    perceptron = [uniform(-0.05, 0.05)
                                  for w in range(self.size[l - 1] + 1)
                                  ]
                    
                    layer.append(perceptron) 
            
            self.weights.append(layer)

    
    def copy(self):
        
        c = deepcopy(self)
        
        return c

        
    def outputs(self, inputs: List) -> Outputs:
        
        assert len(inputs) == self.input_size
        
        result = []

        for l in range(len(self.size)):
            
            layer = []
            
            if l == 0:
                for p in range(self.size[l]):
                    
                    w = self.weights[l][p]
                    x = inputs
                    
                    net = dot(w[:-1], x) + w[-1] # the threshold.
                    o = self.trans_function(net)
                    
                    layer.append(o)
            
            else:
                for p in range(self.size[l]):
                    
                    w = self.weights[l][p]
                    x = result[-1]
                    
                    net = dot(w[:-1], x) + w[-1] # the threshold.
                    o = self.trans_function(net)
                    
                    layer.append(o)
            
            result.append(layer)
        
        return result